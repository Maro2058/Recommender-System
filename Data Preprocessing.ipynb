{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T21:15:44.473467Z",
     "start_time": "2025-05-23T21:15:44.457117Z"
    }
   },
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Get your kaggle.json file:\n",
    "- Go to https://www.kaggle.com/account where account is ur account name\n",
    "- Scroll to the API section\n",
    "- Click Create New API Token\n",
    "- This downloads kaggle.json to your computer (usually in Downloads folder)\n",
    "\n",
    "\n",
    "2. Put kaggle.json in the right folder\n",
    "- Move the file to this folder:\n",
    "    C:\\Users\\Morad Elshorbagy\\\\.kaggle\\\n",
    "\n",
    "If the .kaggle folder doesnâ€™t exist, create it manually"
   ],
   "id": "fe131ba937477bb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:16:14.676384Z",
     "start_time": "2025-05-23T21:16:14.669324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 0: Setup Kaggle API and download dataset ZIP ===\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "dataset_zip = 'the-movies-dataset.zip'\n",
    "output_folder = 'Data'\n",
    "\n",
    "# Download the dataset ZIP only if not already downloaded\n",
    "if not os.path.exists(dataset_zip):\n",
    "    print(\"Downloading dataset ZIP...\")\n",
    "    api.dataset_download_files('rounakbanik/the-movies-dataset', path='.', unzip=False)\n",
    "else:\n",
    "    print(\"Dataset ZIP already downloaded.\")"
   ],
   "id": "43f182751c243340",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ZIP already downloaded.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:16:35.732552Z",
     "start_time": "2025-05-23T21:16:35.194487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create data folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === STEP 1: Extract all necessary files (only if missing) ===\n",
    "needed_files = ['ratings.csv', 'movies_metadata.csv', 'credits.csv', 'keywords.csv']\n",
    "existing_files = os.listdir(output_folder)\n",
    "\n",
    "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "    for file in needed_files:\n",
    "        if file not in existing_files:\n",
    "            print(f\"Extracting {file}...\")\n",
    "            zip_ref.extract(file, path=output_folder)\n",
    "        else:\n",
    "            print(f\"{file} already extracted.\")\n",
    "\n",
    "print(\"Extraction complete.\\n\")"
   ],
   "id": "74c72c26997cc600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings.csv already extracted.\n",
      "movies_metadata.csv already extracted.\n",
      "Extracting credits.csv...\n",
      "Extracting keywords.csv...\n",
      "Extraction complete.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:16:58.490065Z",
     "start_time": "2025-05-23T21:16:50.179525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 2: Load datasets ===\n",
    "print(\"Loading datasets...\")\n",
    "movies = pd.read_csv(os.path.join(output_folder, 'movies_metadata.csv'), low_memory=False)\n",
    "ratings = pd.read_csv(os.path.join(output_folder, 'ratings.csv'))\n",
    "credits = pd.read_csv(os.path.join(output_folder, 'credits.csv'))\n",
    "keywords = pd.read_csv(os.path.join(output_folder, 'keywords.csv'))\n",
    "print(\"Datasets loaded.\\n\")"
   ],
   "id": "314407a2338f259e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:24:45.554513Z",
     "start_time": "2025-05-23T21:24:45.536512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect structure of all datasets\n",
    "print(\"movies_metadata.csv columns:\\n\", movies.columns)\n",
    "print(\"ratings.csv columns:\\n\", ratings.columns)\n",
    "print(\"credits.csv columns:\\n\", credits.columns)\n",
    "print(\"keywords.csv columns:\\n\", keywords.columns)"
   ],
   "id": "a052862b82802fe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_metadata.csv columns:\n",
      " Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='object')\n",
      "ratings.csv columns:\n",
      " Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n",
      "credits.csv columns:\n",
      " Index(['cast', 'crew', 'id'], dtype='object')\n",
      "keywords.csv columns:\n",
      " Index(['id', 'keywords'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:17:07.042308Z",
     "start_time": "2025-05-23T21:17:06.882665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 3: Make copies to keep originals intact ===\n",
    "movies_clean = movies.copy()\n",
    "ratings_clean = ratings.copy()\n",
    "credits_clean = credits.copy()\n",
    "keywords_clean = keywords.copy()"
   ],
   "id": "59d66d7a635919b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:17:21.455152Z",
     "start_time": "2025-05-23T21:17:21.445596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 4: Define helper functions ===\n",
    "def parse_json_column(json_str):\n",
    "    \"\"\"Parse JSON-like string to list of names.\"\"\"\n",
    "    try:\n",
    "        items = ast.literal_eval(json_str)\n",
    "        return [item['name'] for item in items]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "def safe_int_conversion(val):\n",
    "    \"\"\"Safely convert to int, return None if fails.\"\"\"\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return None"
   ],
   "id": "c1b6600924974de6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:19:02.834594Z",
     "start_time": "2025-05-23T21:18:28.362248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 5: Clean movies metadata ===\n",
    "print(\"Cleaning movies metadata...\")\n",
    "# Convert budget and revenue to numeric, fill NaN with 0\n",
    "movies_clean['budget'] = pd.to_numeric(movies_clean['budget'], errors='coerce').fillna(0)\n",
    "movies_clean['revenue'] = pd.to_numeric(movies_clean['revenue'], errors='coerce').fillna(0)\n",
    "\n",
    "# Drop rows missing critical info\n",
    "movies_clean = movies_clean.dropna(subset=['title', 'id'])\n",
    "\n",
    "# Convert 'id' to numeric and drop invalid rows\n",
    "movies_clean['id'] = pd.to_numeric(movies_clean['id'], errors='coerce')\n",
    "movies_clean = movies_clean.dropna(subset=['id'])\n",
    "movies_clean['id'] = movies_clean['id'].astype(int)\n",
    "\n",
    "# Parse genres column (JSON string) into list of genre names\n",
    "movies_clean['genres'] = movies_clean['genres'].apply(parse_json_column)\n",
    "# Replace empty genres lists with ['Unknown']\n",
    "movies_clean['genres'] = movies_clean['genres'].apply(lambda x: x if x else ['Unknown'])\n",
    "print(\"Movies metadata cleaned.\\n\")\n",
    "\n",
    "# === STEP 6: Clean ratings data ===\n",
    "print(\"Cleaning ratings data...\")\n",
    "# Drop duplicates (same userId, movieId)\n",
    "ratings_clean = ratings_clean.drop_duplicates(subset=['userId', 'movieId'])\n",
    "# Drop rows with missing essential columns\n",
    "ratings_clean = ratings_clean.dropna(subset=['userId', 'movieId', 'rating'])\n",
    "# Convert types properly\n",
    "ratings_clean['userId'] = ratings_clean['userId'].astype(int)\n",
    "ratings_clean['movieId'] = ratings_clean['movieId'].astype(int)\n",
    "ratings_clean['rating'] = ratings_clean['rating'].astype(float)\n",
    "print(\"Ratings data cleaned.\\n\")\n",
    "# === STEP 7: Clean credits data ===\n",
    "print(\"Cleaning credits data...\")\n",
    "credits_clean['cast'] = credits_clean['cast'].apply(parse_json_column)\n",
    "credits_clean['crew'] = credits_clean['crew'].apply(parse_json_column)\n",
    "\n",
    "credits_clean['id'] = credits_clean['id'].apply(safe_int_conversion)\n",
    "credits_clean = credits_clean.dropna(subset=['id'])\n",
    "credits_clean['id'] = credits_clean['id'].astype(int)\n",
    "print(\"Credits data cleaned.\\n\")\n",
    "\n",
    "# === STEP 8: Clean keywords data ===\n",
    "print(\"Cleaning keywords data...\")\n",
    "keywords_clean['keywords'] = keywords_clean['keywords'].apply(parse_json_column)\n",
    "\n",
    "keywords_clean['id'] = keywords_clean['id'].apply(safe_int_conversion)\n",
    "keywords_clean = keywords_clean.dropna(subset=['id'])\n",
    "keywords_clean['id'] = keywords_clean['id'].astype(int)\n",
    "print(\"Keywords data cleaned.\\n\")"
   ],
   "id": "8e83d628dd36897f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning movies metadata...\n",
      "Movies metadata cleaned.\n",
      "\n",
      "Cleaning ratings data...\n",
      "Ratings data cleaned.\n",
      "\n",
      "Cleaning credits data...\n",
      "Credits data cleaned.\n",
      "\n",
      "Cleaning keywords data...\n",
      "Keywords data cleaned.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:19:33.498528Z",
     "start_time": "2025-05-23T21:19:19.990051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 9: Merge datasets ===\n",
    "print(\"Merging datasets...\")\n",
    "\n",
    "# Merge movies with credits (cast & crew)\n",
    "movies_full = pd.merge(movies_clean, credits_clean[['id', 'cast', 'crew']], on='id', how='left')\n",
    "\n",
    "# Merge movies_full with keywords\n",
    "movies_full = pd.merge(movies_full, keywords_clean[['id', 'keywords']], on='id', how='left')\n",
    "\n",
    "# Merge ratings with movies (to get movie metadata for ratings)\n",
    "ratings_movies = pd.merge(ratings_clean, movies_clean, left_on='movieId', right_on='id', how='inner')\n",
    "\n",
    "print(\"Datasets merged.\\n\")"
   ],
   "id": "381190ed31abe355",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging datasets...\n",
      "Datasets merged.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:19:46.482005Z",
     "start_time": "2025-05-23T21:19:46.460999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 10: Summary info ===\n",
    "print(f\"Movies dataset shape: {movies_clean.shape}\")\n",
    "print(f\"Ratings dataset shape: {ratings_clean.shape}\")\n",
    "print(f\"Credits dataset shape: {credits_clean.shape}\")\n",
    "print(f\"Keywords dataset shape: {keywords_clean.shape}\")\n",
    "print(f\"Movies full dataset (with credits & keywords) shape: {movies_full.shape}\")\n",
    "print(f\"Ratings merged with movies shape: {ratings_movies.shape}\\n\")"
   ],
   "id": "ca894aa0d612f851",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies dataset shape: (45460, 24)\n",
      "Ratings dataset shape: (26024289, 4)\n",
      "Credits dataset shape: (45476, 3)\n",
      "Keywords dataset shape: (46419, 2)\n",
      "Movies full dataset (with credits & keywords) shape: (46625, 27)\n",
      "Ratings merged with movies shape: (11437637, 28)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:23:47.285009Z",
     "start_time": "2025-05-23T21:20:03.606610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === STEP 11: Save cleaned data to CSV for reuse ===\n",
    "movies_full.to_csv(os.path.join(output_folder, 'movies_full_clean.csv'), index=False)\n",
    "ratings_movies.to_csv(os.path.join(output_folder, 'ratings_movies_clean.csv'), index=False)\n",
    "\n",
    "print(f\"Cleaned datasets saved in '{output_folder}' folder.\")"
   ],
   "id": "80c0583baf3f9d08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets saved in 'Data' folder.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
